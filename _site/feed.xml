

<feed xmlns="http://www.w3.org/2005/Atom">
  <id>http://localhost:4000/</id>
  <title>Code with Linh</title>
  <subtitle>Chia sẻ kiến thức về Machine learning và Deep learning trong sản xuất công nghiệp</subtitle>
  <updated>2023-12-14T23:13:17+08:00</updated>
  <author>
    <name>Linh H. Truong</name>
    <uri>http://localhost:4000/</uri>
  </author>
  <link rel="self" type="application/atom+xml" href="http://localhost:4000/feed.xml"/>
  <link rel="alternate" type="text/html" hreflang="en"
    href="http://localhost:4000/"/>
  <generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator>
  <rights> © 2023 Linh H. Truong </rights>
  <icon>//assets/img/favicons/favicon.ico</icon>
  <logo>//assets/img/favicons/favicon-96x96.png</logo>


  
  <entry>
    <title>Auto-encoder - From AE to VAE with Pytorch</title>
    <link href="http://localhost:4000/posts/auto-encoder-from-ae-to-vae-with-pytorch/" rel="alternate" type="text/html" title="Auto-encoder - From AE to VAE with Pytorch" />
    <published>2023-12-14T00:00:00+08:00</published>
  
    <updated>2023-12-14T00:00:00+08:00</updated>
  
    <id>http://localhost:4000/posts/auto-encoder-from-ae-to-vae-with-pytorch/</id>
    <content src="http://localhost:4000/posts/auto-encoder-from-ae-to-vae-with-pytorch/" />
    <author>
      <name>hoanglinh</name>
    </author>

  
    
    <category term="Deep Learning" />
    
  

  
    <summary>
      





      Auto-encoders serve as versatile tools in deep learning due to their ability to learn efficient representations of data. Their primary motivation lies in dimensionality reduction and feature learning, allowing for the extraction of meaningful features from raw data. By encoding input data into a compressed representation and subsequently reconstructing it, auto-encoders aid in tasks like denois...
    </summary>
  

  </entry>

</feed>


