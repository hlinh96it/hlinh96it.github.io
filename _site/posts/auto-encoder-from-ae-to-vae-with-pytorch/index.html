<!DOCTYPE html>









<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="en"
  
    data-mode="light"
  
>

  <!--
  The Head
-->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  

    

    

  

  

  

  
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Auto-encoder - From AE to VAE with Pytorch" />
<meta name="author" content="Linh H. Truong" />
<meta property="og:locale" content="en" />
<meta name="description" content="Auto-encoders serve as versatile tools in deep learning due to their ability to learn efficient representations of data. Their primary motivation lies in dimensionality reduction and feature learning, allowing for the extraction of meaningful features from raw data. By encoding input data into a compressed representation and subsequently reconstructing it, auto-encoders aid in tasks like denoising, anomaly detection, and generative modeling. Their self-supervised nature, where they learn from unlabeled data, makes them valuable in scenarios where labeled data is scarce or costly. Moreover, their adaptability across various domains, from image and text data to more complex sequential data, underscores their significance in modern deep learning architectures." />
<meta property="og:description" content="Auto-encoders serve as versatile tools in deep learning due to their ability to learn efficient representations of data. Their primary motivation lies in dimensionality reduction and feature learning, allowing for the extraction of meaningful features from raw data. By encoding input data into a compressed representation and subsequently reconstructing it, auto-encoders aid in tasks like denoising, anomaly detection, and generative modeling. Their self-supervised nature, where they learn from unlabeled data, makes them valuable in scenarios where labeled data is scarce or costly. Moreover, their adaptability across various domains, from image and text data to more complex sequential data, underscores their significance in modern deep learning architectures." />
<link rel="canonical" href="http://localhost:4000/posts/auto-encoder-from-ae-to-vae-with-pytorch/" />
<meta property="og:url" content="http://localhost:4000/posts/auto-encoder-from-ae-to-vae-with-pytorch/" />
<meta property="og:site_name" content="Code with Linh" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-12-14T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Auto-encoder - From AE to VAE with Pytorch" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Linh H. Truong","url":"https://github.com/hlinh96it"},"dateModified":"2023-12-14T00:00:00+08:00","datePublished":"2023-12-14T00:00:00+08:00","description":"Auto-encoders serve as versatile tools in deep learning due to their ability to learn efficient representations of data. Their primary motivation lies in dimensionality reduction and feature learning, allowing for the extraction of meaningful features from raw data. By encoding input data into a compressed representation and subsequently reconstructing it, auto-encoders aid in tasks like denoising, anomaly detection, and generative modeling. Their self-supervised nature, where they learn from unlabeled data, makes them valuable in scenarios where labeled data is scarce or costly. Moreover, their adaptability across various domains, from image and text data to more complex sequential data, underscores their significance in modern deep learning architectures.","headline":"Auto-encoder - From AE to VAE with Pytorch","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/auto-encoder-from-ae-to-vae-with-pytorch/"},"url":"http://localhost:4000/posts/auto-encoder-from-ae-to-vae-with-pytorch/"}</script>
<!-- End Jekyll SEO tag -->

  

  <title>Auto-encoder - From AE to VAE with Pytorch | Code with Linh
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/img/favicons/site.webmanifest">
<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="Code with Linh">
<meta name="application-name" content="Code with Linh">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  

    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin>
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
    

    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">

  

  <!-- GA -->
  

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.1/css/all.min.css">

  <link rel="stylesheet" href="/assets/css/style.css">

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css">
  

  
    <!-- Manific Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css">
  

  <!-- JavaScript -->

  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.1/dist/jquery.min.js"></script>

  
</head>


  <body data-spy="scroll" data-target="#toc" data-topbar-visible="true">

    <!--
  The Side Bar
-->

<div id="sidebar" class="d-flex flex-column align-items-end">
  <div class="profile-wrapper text-center">
    <div id="avatar">
      <a href="/" class="mx-auto">
        
          
          <img src="/hero.png" alt="avatar" onerror="this.style.display='none'">
        
      </a>
    </div>

    <div class="site-title">
      <a href="/">Code with Linh</a>
    </div>
    <div class="site-subtitle font-italic">Everything comes from an idea. Just do it and keep your motivation</div>

  </div><!-- .profile-wrapper -->

  <ul class="w-100">

    <!-- home -->
    <li class="nav-item">
      <a href="/" class="nav-link">
        <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i>
        <span>HOME</span>
      </a>
    </li>
    <!-- the real tabs -->
    
    <li class="nav-item">
      <a href="/categories/" class="nav-link">
        <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>CATEGORIES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/tags/" class="nav-link">
        <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>TAGS</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/archives/" class="nav-link">
        <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>ARCHIVES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/about/" class="nav-link">
        <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>ABOUT</span>
      </a>
    </li> <!-- .nav-item -->
    

  </ul> <!-- ul.nav.flex-column -->

  <div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center">

    

    
      

      
      <a href="https://github.com/hlinh96it" aria-label="github"
        
        
          
          target="_blank"
        

        

        rel="noopener">
        <i class="fab fa-github"></i>
      </a>
      

    
      

      
      <a href="https://twitter.com/" aria-label="twitter"
        
        
          
          target="_blank"
        

        

        rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
      

    
      

      
      <a href="
          javascript:location.href = 'mailto:' + ['hoanglinh96nl','gmail.com'].join('@')" aria-label="email"
        
        

        

        >
        <i class="fas fa-envelope"></i>
      </a>
      

    
      

      
      <a href="/feed.xml" aria-label="rss"
        
        

        

        >
        <i class="fas fa-rss"></i>
      </a>
      

    

  </div> <!-- .sidebar-bottom -->

</div><!-- #sidebar -->


    <!--
  The Top Bar
-->

<div id="topbar-wrapper">
  <div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4">
    <span id="breadcrumb">

    

    

      

        
          <span>
            <a href="/">
              Home
            </a>
          </span>

        

      

        

      

        

          
            <span>Auto-encoder - From AE to VAE with Pytorch</span>
          

        

      

    

    </span><!-- endof #breadcrumb -->

    <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i>

    <div id="topbar-title">
      Post
    </div>

    <i id="search-trigger" class="fas fa-search fa-fw"></i>
    <span id="search-wrapper" class="align-items-center">
      <i class="fas fa-search fa-fw"></i>
      <input class="form-control" id="search-input" type="search"
        aria-label="search" autocomplete="off" placeholder="Search...">
    </span>
    <span id="search-cancel" >Cancel</span>
  </div>

</div>


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div id="main" class="container pl-xl-4 pr-xl-4">
        





<div class="row">

  <!-- core -->
  <div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4">
    <div class="post pl-1 pr-1 pl-md-2 pr-md-2">

    

    
      
      
        <!--
  Refactor the HTML structure.
-->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->


<!-- images -->




  
  

  <!-- CDN URL -->
  

  <!-- Add image path -->
  

  
    
      
      
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      

    
      

      
      
      

      

    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    <!-- make sure the `<img>` is wrapped by `<a>` -->
    

    
      <!-- create the image wrapper -->
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      

    
      

      
      
      

      

    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    <!-- make sure the `<img>` is wrapped by `<a>` -->
    

    
      <!-- create the image wrapper -->
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      

    
      

      
      
      

      

    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    <!-- make sure the `<img>` is wrapped by `<a>` -->
    

    
      <!-- create the image wrapper -->
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      

    
      

      
      
      

      

    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    <!-- make sure the `<img>` is wrapped by `<a>` -->
    

    
      <!-- create the image wrapper -->
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      

    
      

      
      
      

      

    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    <!-- make sure the `<img>` is wrapped by `<a>` -->
    

    
      <!-- create the image wrapper -->
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      

    
      

      
      
      

      

    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    <!-- make sure the `<img>` is wrapped by `<a>` -->
    

    
      <!-- create the image wrapper -->
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      

    
      

      
      
      

      

    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    <!-- make sure the `<img>` is wrapped by `<a>` -->
    

    
      <!-- create the image wrapper -->
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      

    
      

      
      
      

      

    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    <!-- make sure the `<img>` is wrapped by `<a>` -->
    

    
      <!-- create the image wrapper -->
      
    

    <!-- combine -->
    

  

  



<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  

  
  

  




<!-- return -->

<h1 data-toc-skip>Auto-encoder - From AE to VAE with Pytorch</h1>

<div class="post-meta text-muted">
    <!-- published date -->
    <span>
      Posted
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class=""
    data-ts="1702483200"
    data-df="ll"
    data-toggle="tooltip" data-placement="bottom">
  Dec 14, 2023
</em>

    </span>

    <!-- lastmod date -->
    

  

  <div class="d-flex justify-content-between">
    <!-- author(s) -->
    <span>
      

      By

      <em>
      
        
          <a href="https://github.com/hlinh96it">Linh H. Truong</a>
          
        
      
      </em>
    </span>

    <div>
      <!-- page views -->
      

      <!-- read time -->
      <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->



<!-- words per minute  -->










<!-- return element -->
<span class="readtime" data-toggle="tooltip" data-placement="bottom"
  title="2870 words">
  <em>15 min</em> read</span>

    </div>

  </div> <!-- .d-flex -->

</div> <!-- .post-meta -->

<div class="post-content">
  <p><strong>Auto-encoders</strong> serve as versatile tools in <strong>deep learning</strong> due to their ability to learn efficient representations of data. Their primary motivation lies in <strong>dimensionality reduction</strong> and <strong>feature learning</strong>, allowing for the extraction of meaningful features from raw data. By encoding input data into a compressed representation and subsequently reconstructing it, auto-encoders aid in tasks like <strong>denoising</strong>, <strong>anomaly detection</strong>, and <strong>generative modeling</strong>. Their self-supervised nature, where they learn from unlabeled data, makes them valuable in scenarios where labeled data is scarce or costly. Moreover, their adaptability across various domains, from image and text data to more complex sequential data, underscores their significance in modern deep learning architectures.</p>

<h2 id="auto-encoder-fundamentals"><span class="mr-2">Auto-Encoder Fundamentals</span><a href="#auto-encoder-fundamentals" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<hr />
<p>An auto-encoder comprises two primary components: the encoder, represented as  $f(\phi)$ , and the decoder, denoted as $g(\theta)$ . The encoder function  $f(\phi)$  compresses the input data  $x$  into a lower-dimensional latent space representation called the bottleneck, denoted as  $z$ . This encoding process aims to capture the most essential features of the input. Subsequently, the decoder function  $g(\theta)$  reconstructs the original input from this bottleneck representation. The auto-encoder’s training involves minimizing a loss function that measures the discrepancy between the input and the reconstructed output.</p>

<p>The <strong>reconstruction loss</strong> can be computed using various metrics, commonly employing the <strong>mean squared error (MSE)</strong> for continuous data or <strong>binary cross-entropy</strong> for binary data. For instance, the MSE loss function for a set of $N$ training samples can be expressed as:</p>

\[L(\phi, \theta) = \frac{1}{N} \sum_{i=1}^{N} || x^{(i)} - g(\theta)(f(\phi)(x^{(i)})) ||^2\]

<p>Here,  $x^{(i)}$  represents the  $i$ th input sample,  $f(\phi)(x^{(i)})$  is the encoding of  $x^{(i)}$  to the bottleneck  $z^{(i)}$ , and  $g(\theta)(z^{(i)})$  is the reconstruction of  $x^{(i)}$  from the bottleneck representation. The goal during training is to adjust the encoder and decoder parameters  $\phi$  and  $\theta$  to minimize this loss, thereby improving the accuracy of the reconstructed output compared to the original input.</p>

<p><a href="/posts_media/2023-12-14-auto-encoder-from-ae-to-vae-with-pytorch/Untitled.png" class="popup img-link "><img data-src="/posts_media/2023-12-14-auto-encoder-from-ae-to-vae-with-pytorch/Untitled.png" alt="Illustration of autoencoder model architecture. Source: [https://lilianweng.github.io/posts/2018-08-12-vae/](https://lilianweng.github.io/posts/2018-08-12-vae/)" class="lazyload" data-proofer-ignore></a><em>Illustration of autoencoder model architecture. Source: <a href="https://lilianweng.github.io/posts/2018-08-12-vae/">https://lilianweng.github.io/posts/2018-08-12-vae/</a></em></p>

<p>The <strong>encoder network</strong> serves a purpose akin to dimensionality reduction methods like Principal Component Analysis (PCA) or Matrix Factorization (MF). It condenses the input data into a compressed or encoded representation, reducing its dimensionality. This reduction helps in capturing the most relevant and <strong>essential features of the data while discarding less critical information</strong>. This process is crucial as it simplifies the data representation, making it more manageable and efficient for subsequent analysis or processing.</p>

<h2 id="denoising-autoencoder"><span class="mr-2">Denoising Autoencoder</span><a href="#denoising-autoencoder" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<hr />

<p>In a <strong>denoising autoencoder</strong>, the primary objective is to reconstruct clean data from corrupted or noisy input. This approach aids in learning robust and meaningful representations by forcing the model to capture essential features while filtering out noise.</p>

<p>The <strong>need for denoising</strong> arises from the desire to make the learned representation more robust against noise present in real-world data. By training on corrupted input and expecting the model to recover the original, clean data, the denoising autoencoder becomes adept at extracting salient features while filtering out irrelevant or noisy information.</p>

<p><a href="/posts_media/2023-12-14-auto-encoder-from-ae-to-vae-with-pytorch/Untitled 2.png" class="popup img-link "><img data-src="/posts_media/2023-12-14-auto-encoder-from-ae-to-vae-with-pytorch/Untitled 2.png" alt="Illustration of denoising autoencoder model architecture. Source: [https://lilianweng.github.io/posts/2018-08-12-vae/](https://lilianweng.github.io/posts/2018-08-12-vae/)" class="lazyload" data-proofer-ignore></a><em>Illustration of denoising autoencoder model architecture. Source: <a href="https://lilianweng.github.io/posts/2018-08-12-vae/">https://lilianweng.github.io/posts/2018-08-12-vae/</a></em></p>

<p>The modification in the loss function involves comparing the reconstructed output to the original, uncorrupted input. Assuming an additive random noise  $\epsilon$  is applied to the input  $x$  to generate the corrupted input  $x_{\text{corrupted}}$ , the denoising autoencoder aims to minimize the reconstruction error between the reconstructed output and the original, uncorrupted input.</p>

<p>The adjusted loss function using mean squared error (MSE) for a set of $N$ training samples can be expressed as:</p>

\[\begin{equation}
L(\phi, \theta) = \frac{1}{N} \sum_{i=1}^{N} || x^{(i)} - g(\theta)(f(\phi)(x_{\text{corrupted}}^{(i)})) ||^2
\end{equation}\]

<p>To illustrate how noise is added to the input, assuming Gaussian noise with mean  $\mu$  and standard deviation  $\sigma$  is added to each element of the input  $x$  to generate the corrupted input  $x_{\text{corrupted}}$ , it can be represented as:</p>

\[\begin{equation}
x_{\text{corrupted}} = x + \epsilon, \quad \text{where} \quad \epsilon \sim \mathcal{N}(\mu, \sigma^2)
\end{equation}\]

<p>Here,  $x^{(i)}$  denotes the  $i$ th input sample,  $f(\phi)(x_{\text{corrupted}}^{(i)})$  represents the encoding of the corrupted input to the bottleneck  $z^{(i)}$ , and  $g(\theta)(z^{(i)})$  signifies the reconstruction of  $x^{(i)}$  from the bottleneck representation. The denoising autoencoder, by learning to reconstruct clean data from noisy inputs, encourages the model to capture robust and meaningful features while enhancing its ability to filter out unwanted noise in the data.</p>

<h2 id="sparse-auto-encoder"><span class="mr-2">Sparse Auto-Encoder</span><a href="#sparse-auto-encoder" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<hr />

<p>Sparse auto-encoders aim to introduce <strong>sparsity in the learned representations</strong>, meaning that only a <strong>few units in the network are activated at a time</strong>. This sparsity constraint forces the model to learn more efficient and selective representations, focusing on the most important features in the data. The sparsity constraint encourages the autoencoder to use only a limited number of neurons in the encoding process, which can lead to better generalization, reduced overfitting, and improved interpretability of the learned features.</p>

<p>In a sparse autoencoder, the loss function is modified to include a <strong>sparsity term</strong>. The overall loss function now comprises two components: the reconstruction loss and the sparsity regularization term. The sparsity term encourages the activation of only a small fraction $\rho$ of units in the hidden layer.</p>

<p>The loss function for a sparse autoencoder with $N$ training samples can be expressed as follows:</p>

\[\begin{equation}
L(\phi, \theta) = \frac{1}{N} \sum_{i=1}^{N} || x^{(i)} - g(\theta)(f(\phi)(x^{(i)})) ||^2 + \lambda \sum_{j=1}^{K} \text{KL}(\rho || \hat{\rho}_j)
\end{equation}\]

<p>Where:</p>

<ul>
  <li>$x^{(i)}$  represents the  $i$ th input sample.</li>
  <li>$f(\phi)(x^{(i)})$  denotes the encoding of  $x^{(i)}$  to the bottleneck.</li>
  <li>$g(\theta)(z^{(i)})$  represents the reconstruction of  $x^{(i)}$  from the bottleneck representation.</li>
  <li>$K$  is the number of units in the hidden layer.</li>
  <li>$\lambda$  is the regularization parameter controlling the impact of the sparsity term.</li>
  <li>$\text{KL}$  denotes the Kullback-Leibler divergence, measuring the difference between the desired sparsity  $\rho$  and the actual average activation  $\hat{\rho}_j$  of each neuron in the hidden layer.</li>
</ul>

<p>The sparsity term  $\text{KL}$ can be defined as:</p>

\[\begin{equation}
\text{KL}(\rho || \hat{\rho}_j) = \rho \log \left( \frac{\rho}{\hat{\rho}_j} \right) + (1 - \rho) \log \left( \frac{1 - \rho}{1 - \hat{\rho}_j} \right)
\end{equation}\]

<p>Here,  $\rho$  represents the desired sparsity level, and  $\hat{\rho}_j$  is the average activation of neuron  $j$  in the hidden layer over the training set. Let say, there are $s_l$ neurons in the $l$-th layer and the activation function of $j$-th neuron in this layer is $a_j^{(l)}(.)$ where $j=1,..s_l$, $\hat{\rho}_j^{(l)}$ can be calculated as:</p>

\[\begin{equation}\hat{\rho}_j^{(l)} = \frac{1}{n} \sum_{i=1}^n [a_j^{(l)}(\mathbf{x}^{(i)})] \approx \rho \end{equation}\]

<p>By incorporating the sparsity term in the loss function, the sparse autoencoder encourages the network to learn sparse and informative representations, promoting more efficient and selective encoding of input data.</p>

<h2 id="vae-variational-autoencoder"><span class="mr-2">VAE: Variational Autoencoder</span><a href="#vae-variational-autoencoder" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<hr />

<p>Variational Autoencoders (VAEs) address the limitations of traditional autoencoders by enabling the generation of new data samples. They aim to learn a latent space representation that not only captures meaningful features but also allows for the generation of new, realistic data points by sampling from the learned distribution. VAEs achieve this by imposing a specific structure on the latent space, making it follow a probabilistic distribution.</p>

<p>In a VAE, the goal is to <strong>learn a probability distribution</strong> over the latent space, which is typically assumed to follow a Gaussian distribution. The model learns to <strong>encode input data into a probability distribution</strong>, and during the decoding process, it generates new samples by sampling from this distribution.</p>

<p><a href="/posts_media/2023-12-14-auto-encoder-from-ae-to-vae-with-pytorch/Untitled 2.png" class="popup img-link "><img data-src="/posts_media/2023-12-14-auto-encoder-from-ae-to-vae-with-pytorch/Untitled 2.png" alt="Variational Autoencoder. Source: [https://lilianweng.github.io/posts/2018-08-12-vae/](https://lilianweng.github.io/posts/2018-08-12-vae/)" class="lazyload" data-proofer-ignore></a><em>Variational Autoencoder. Source: <a href="https://lilianweng.github.io/posts/2018-08-12-vae/">https://lilianweng.github.io/posts/2018-08-12-vae/</a></em></p>

<p>The VAE’s loss function comprises two components: a reconstruction loss similar to traditional autoencoders and a regularization term that enforces the latent space to follow a specific distribution (usually a standard Gaussian distribution).</p>

<p>The loss function for a VAE with $N$ training samples can be expressed as follows:</p>

\[\begin{equation}
L(\phi, \theta) = -\frac{1}{N} \sum_{i=1}^{N} \mathbb{E}{z \sim q\phi(z|x^{(i)})} \left[ \log p_\theta(x^{(i)}|z) \right] + \text{KL}(q_\phi(z|x^{(i)}) || p(z))
\end{equation}\]

<p>Where</p>

<ul>
  <li>$x^{(i)}$  represents the  $i$ th input sample.</li>
  <li>$q_\phi(z|x^{(i)})$  denotes the approximate posterior distribution (encoder) that maps input  $x^{(i)}$  to a distribution over the latent space  $z$ .</li>
  <li>$p_\theta(x^{(i)}|z)$  represents the likelihood of generating  $x^{(i)}$  from the latent variable  $z$  (decoder).</li>
  <li>$p(z)$  is the prior distribution assumed over the latent space, often chosen as a standard Gaussian distribution.</li>
  <li>$\text{KL}$  denotes the Kullback-Leibler divergence, measuring the difference between the approximate posterior  $q_\phi(z|x^{(i)})$  and the prior  $p(z)$ .</li>
</ul>

<p>The first term in the loss function is the reconstruction loss, ensuring the fidelity of the generated output to the original input. The second term is the KL divergence, encouraging the distribution of latent variables to approximate the chosen prior distribution. This regularization term helps in shaping the latent space to be continuous and smooth, facilitating the generation of new data samples by sampling from this learned distribution.</p>

<blockquote class="prompt-info">
  <p>VAEs enable both effective representation learning and generative capabilities, allowing for the creation of novel data points from the learned latent space distribution.</p>
</blockquote>

<h3 id="reparameterization-trick"><span class="mr-2">Reparameterization Trick</span><a href="#reparameterization-trick" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>In a VAE, the goal is to learn a latent space representation for input data that can generate similar data points. This involves sampling from a probability distribution (typically Gaussian) in the latent space. The challenge is that directly sampling from this distribution introduces randomness, making it challenging to compute gradients and perform backpropagation during training.</p>

<p>Reparameterization is a technique used in variational autoencoders (VAEs) to enable the training of the model through backpropagation while dealing with stochasticity in the latent space sampling process. Reparameterization addresses this issue by <strong>separating the stochasticity</strong> of the sampling process from the parameters that are being learned. Instead of directly sampling from the distribution, the technique reparameterizes the random variable using a deterministic transformation based on the distribution’s parameters (mean and standard deviation).</p>

<p>For instance, in a VAE with a Gaussian latent space, rather than directly sampling from a Gaussian distribution with mean $\mu$ and standard deviation $\sigma$, we sample from a standard normal distribution $\boldsymbol{\epsilon} \sim \mathcal{N}(0, \boldsymbol{I})$ and then transform the sampled value using the mean and standard deviation obtained from the encoder.</p>

<p><a href="/posts_media/2023-12-14-auto-encoder-from-ae-to-vae-with-pytorch/Untitled 3.png" class="popup img-link "><img data-src="/posts_media/2023-12-14-auto-encoder-from-ae-to-vae-with-pytorch/Untitled 3.png" alt="Illustration of how the reparameterization trick makes the $z$ sampling process trainable.(Image source: Slide 12 in Kingma’s NIPS 2015 workshop [talk](http://dpkingma.com/wordpress/wp-content/uploads/2015/12/talk_nips_workshop_2015.pdf))" class="lazyload" data-proofer-ignore></a><em>Illustration of how the reparameterization trick makes the $z$ sampling process trainable.(Image source: Slide 12 in Kingma’s NIPS 2015 workshop <a href="http://dpkingma.com/wordpress/wp-content/uploads/2015/12/talk_nips_workshop_2015.pdf">talk</a>)</em></p>

<h2 id="implement-vae-with-pytorch"><span class="mr-2">Implement VAE with Pytorch</span><a href="#implement-vae-with-pytorch" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<hr />
<p>Full implement here: <a href="https://github.com/hlinh96it/variational-auto-encoder-basics">https://github.com/hlinh96it/variational-auto-encoder-basics</a></p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">torchvision.datasets</span> <span class="kn">import</span> <span class="n">MNIST</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="n">torchvision.transforms</span> <span class="k">as</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="n">mpl_toolkits.axes_grid1</span> <span class="kn">import</span> <span class="n">ImageGrid</span>
<span class="kn">from</span> <span class="n">torchvision.utils</span> <span class="kn">import</span> <span class="n">save_image</span><span class="p">,</span> <span class="n">make_grid</span>
</pre></td></tr></tbody></table></code></div></div>

<p><strong>Class</strong> <code class="language-plaintext highlighter-rouge">VariationalAE</code> <strong>which inherits from</strong> <code class="language-plaintext highlighter-rouge">nn.Module</code><strong>, making it a PyTorch neural network module.</strong></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">input_dim</code>: Dimensionality of the input data (default is set to the MNIST image size: 28x28 = 784).</li>
  <li><code class="language-plaintext highlighter-rouge">hidden_dim</code>: Number of neurons in the hidden layer (default is 400).</li>
  <li><code class="language-plaintext highlighter-rouge">latent_dim</code>: Dimensionality of the latent space (default is 200).</li>
  <li><code class="language-plaintext highlighter-rouge">device</code>: Device to be used (default is <code class="language-plaintext highlighter-rouge">'mps'</code>) since I used M1 Pro Chip, otherwise please use <code class="language-plaintext highlighter-rouge">'cuda'</code></li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">VariationalAE</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">mps</span><span class="sh">'</span><span class="p">)):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">VariationalAE</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">mean_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">logvar_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p><code class="language-plaintext highlighter-rouge">self.encoder</code>: Sequential neural network consisting of linear layers followed by LeakyReLU activations: Takes the input and maps it through hidden layers to obtain a latent representation and output of this encoder is the latent space representation.</p>

<p><code class="language-plaintext highlighter-rouge">self.mean_layer</code> and <code class="language-plaintext highlighter-rouge">self.logvar_layer</code>: These layers take the latent representation and output the mean and log variance of the Gaussian distribution representing the latent space. In VAEs, the mean and log variance are used to sample latent space points during the encoding process.</p>

<p><code class="language-plaintext highlighter-rouge">self.decoder</code>: Sequential neural network responsible for decoding the sampled latent space points back to the original data space.</p>

<ul>
  <li>Takes the sampled latent space representation and decodes it back to the original input space.</li>
  <li>Comprises linear layers with <code class="language-plaintext highlighter-rouge">LeakyReLU</code> activations and a final sigmoid activation (assuming the input data is pixel values in the range <code class="language-plaintext highlighter-rouge">[0,1]</code>).</li>
</ul>

<p>Regarding <code class="language-plaintext highlighter-rouge">self.mean_layer = nn.Linear(latent_dim, 2)</code>: In a VAE, the mean and log variance layers define the parameters of the approximate posterior distribution over the latent space variables. In this case, the output dimensions are set to 2 to assume a 2-dimensional latent space. The choice of a 2-dimensional latent space is common in VAEs for visualization purposes and to capture essential features of the data distribution in a compressed space.</p>

<p><a href="/posts_media/2023-12-14-auto-encoder-from-ae-to-vae-with-pytorch/Untitled 4.png" class="popup img-link "><img data-src="/posts_media/2023-12-14-auto-encoder-from-ae-to-vae-with-pytorch/Untitled 4.png" alt="Source: [https://www.jeremyjordan.me/variational-autoencoders/](https://www.jeremyjordan.me/variational-autoencoders/)" class="lazyload" data-proofer-ignore></a><em>Source: <a href="https://www.jeremyjordan.me/variational-autoencoders/">https://www.jeremyjordan.me/variational-autoencoders/</a></em></p>

<blockquote class="prompt-info">
  <p>This 2-dimensional latent space enables <strong>easy visualization</strong> and can capture the essential features of the data while allowing easy generation of new samples by sampling from a simple distribution, such as a standard Gaussian.</p>
</blockquote>

<h3 id="forward-method"><span class="mr-2">Forward Method</span><a href="#forward-method" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">reparameterization</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
    <span class="n">x_hat</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span>

<span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">mean_layer</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">self</span><span class="p">.</span><span class="nf">logvar_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span>
</pre></td></tr></tbody></table></code></div></div>

<p>This code defines the forward pass and encoding process for the variational autoencoder (VAE) previously described. Let’s break it down:</p>

<ul>
  <li>Takes an input <code class="language-plaintext highlighter-rouge">x</code> and passes it through the encoder to obtain the mean and log variance of the latent space (<code class="language-plaintext highlighter-rouge">mean</code>, <code class="language-plaintext highlighter-rouge">logvar</code>).</li>
  <li>Utilizes the reparameterization trick to sample from the learned distribution and obtain a latent representation <code class="language-plaintext highlighter-rouge">z</code>.</li>
  <li>Decodes this latent representation <code class="language-plaintext highlighter-rouge">z</code> to reconstruct the input <code class="language-plaintext highlighter-rouge">x</code> and returns the reconstructed input (<code class="language-plaintext highlighter-rouge">x_hat</code>), along with <code class="language-plaintext highlighter-rouge">mean</code> and <code class="language-plaintext highlighter-rouge">logvar</code>.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">reparameterization</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span><span class="p">):</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">logvar</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">logvar</span> <span class="o">*</span> <span class="n">epsilon</span>
</pre></td></tr></tbody></table></code></div></div>

<h3 id="training-loop-for-a-variational-autoencoder-vae"><span class="mr-2">Training loop for a variational autoencoder (VAE)</span><a href="#training-loop-for-a-variational-autoencoder-vae" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">):</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">overall_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>

						<span class="c1"># used to reshape the input x to match the input size expected by the model.
</span>            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
            <span class="n">x_hat</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>

            <span class="n">overall_loss</span> <span class="o">+=</span> <span class="n">loss</span>
            <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">At epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">, loss = </span><span class="si">{</span><span class="n">overall_loss</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p>Trains the VAE model for a specified number of epochs:</p>

<ul>
  <li>Reshapes the input <code class="language-plaintext highlighter-rouge">x</code> to match the model’s input dimensions and moves it to the specified device.</li>
  <li>Performs the forward pass through the model to obtain reconstructed output (<code class="language-plaintext highlighter-rouge">x_hat</code>), mean, and logvar.</li>
  <li>Calculates the loss using the defined <code class="language-plaintext highlighter-rouge">loss_function</code>.</li>
  <li>Computes gradients, performs backpropagation, and updates the model’s weights using the optimizer.</li>
  <li>Accumulates the loss for the entire epoch (<code class="language-plaintext highlighter-rouge">overall_loss</code>).</li>
</ul>

<h3 id="for-calcuating-loss-function-we-use-kullback-leibler-divergence-kld"><span class="mr-2">For calcuating loss function, we use Kullback-Leibler Divergence (KLD)</span><a href="#for-calcuating-loss-function-we-use-kullback-leibler-divergence-kld" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span><span class="p">):</span>
    <span class="n">reproduction_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">binary_cross_entropy</span><span class="p">(</span><span class="n">x_hat</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="sh">'</span><span class="s">sum</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">kld</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">logvar</span> <span class="o">-</span> <span class="n">mean</span><span class="p">.</span><span class="nf">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">logvar</span><span class="p">.</span><span class="nf">exp</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">reproduction_loss</span> <span class="o">+</span> <span class="n">kld</span>
</pre></td></tr></tbody></table></code></div></div>

<p>The <code class="language-plaintext highlighter-rouge">kld</code> term computes the Kullback-Leibler divergence between the learned latent space distribution and a standard normal distribution. It quantifies how much the learned distribution differs from the standard normal distribution.</p>

<ul>
  <li>The formula used here is based on the formula for KLD between two Gaussian distributions in the context of VAEs.</li>
  <li>The <code class="language-plaintext highlighter-rouge">0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())</code> represents the KLD between the approximate posterior (encoded distribution) and the prior distribution (standard normal distribution) in the latent space.</li>
</ul>

<p><a href="/posts_media/2023-12-14-auto-encoder-from-ae-to-vae-with-pytorch/Untitled 5.png" class="popup img-link "><img data-src="/posts_media/2023-12-14-auto-encoder-from-ae-to-vae-with-pytorch/Untitled 5.png" alt="KL divergence have different demands on how to match two distributions. Source: [blog.evjang.com/2016/08/variational-bayes.html](https://blog.evjang.com/2016/08/variational-bayes.html))" class="lazyload" data-proofer-ignore></a><em>KL divergence have different demands on how to match two distributions. Source: <a href="https://blog.evjang.com/2016/08/variational-bayes.html">blog.evjang.com/2016/08/variational-bayes.html</a>)</em></p>

<h3 id="overall-training-process-loading-mnist-dataset"><span class="mr-2">Overall training process: loading MNIST dataset</span><a href="#overall-training-process-loading-mnist-dataset" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>Assuming you have a CUDA-enabled GPU, replace to <code class="language-plaintext highlighter-rouge">'cuda'</code>. If you’re running on a CPU, use **<code class="language-plaintext highlighter-rouge">'cpu**'</code> instead:</p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="nc">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="p">.</span><span class="nc">ToTensor</span><span class="p">()])</span>

<span class="n">path</span> <span class="o">=</span> <span class="sh">'</span><span class="s">mnist-dataset/</span><span class="sh">'</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="nc">MNIST</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="nc">MNIST</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">mps:0</span><span class="sh">'</span><span class="p">)</span>

<span class="n">vae_model</span> <span class="o">=</span> <span class="nc">VariationalAE</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">200</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">vae_model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">vae_model</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p>We now know that all we need to generate an image from the latent space is two float values (mean and variance). Let’s generate some images from the latent space. This is what the latent space looks like for mean and variance values between -1.0 and 1.0:</p>

<p><a href="/posts_media/2023-12-14-auto-encoder-from-ae-to-vae-with-pytorch/Untitled 6.png" class="popup img-link "><img data-src="/posts_media/2023-12-14-auto-encoder-from-ae-to-vae-with-pytorch/Untitled 6.png" alt="Untitled" class="lazyload" data-proofer-ignore></a></p>

<h2 id="vae-vs-generative-arversarial-networks-gan"><span class="mr-2">VAE vs Generative Arversarial Networks (GAN)?</span><a href="#vae-vs-generative-arversarial-networks-gan" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<hr />

<p>Imagine you are an artist who wants to draw a picture of a cat. The VAE (Variational Autoencoder) would help you draw a cat by giving you a set of rules to follow. It tells you what a cat looks like in general, and you try to draw a cat based on those rules. Sometimes, the cat you draw may not look exactly like a real cat, but it’s close.</p>

<p>On the other hand, the GAN (Generative Adversarial Network) works differently. It’s like having two artists competing against each other. One artist, called the generator, tries to draw a cat, and the other artist, called the discriminator, looks at the drawing and tries to tell if it’s a real cat or not. The generator keeps improving its drawings to fool the discriminator, and the discriminator keeps getting better at spotting fake cats. This competition makes the generator really good at drawing cats that look very realistic.</p>

<p><a href="/posts_media/2023-12-14-auto-encoder-from-ae-to-vae-with-pytorch/Untitled 7.png" class="popup img-link "><img data-src="/posts_media/2023-12-14-auto-encoder-from-ae-to-vae-with-pytorch/Untitled 7.png" alt="Simple Architecture of a GAN. Source: [https://www.clickworker.com/ai-glossary/generative-adversarial-networks/](https://www.clickworker.com/ai-glossary/generative-adversarial-networks/)" class="lazyload" data-proofer-ignore></a><em>Simple Architecture of a GAN. Source: <a href="https://www.clickworker.com/ai-glossary/generative-adversarial-networks/">https://www.clickworker.com/ai-glossary/generative-adversarial-networks/</a></em></p>

<p>So, the main difference is that the VAE gives you rules to follow to draw something, while the GAN learns by competition to create things that look very real. Both methods are used for creating new, realistic-looking images, but they work in different ways.</p>

<h2 id="recommended-resources-for-further-learning"><span class="mr-2">Recommended resources for further learning</span><a href="#recommended-resources-for-further-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<hr />
<p>Here are some recommended books for delving into deep learning from scratch:</p>
<ul>
  <li><a href="https://amzn.to/3YZeOAk">Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</a> by Aurélien Géron</li>
  <li><a href="https://amzn.to/40gyjFQ">Deep Learning from Scratch: Building with Python from First Principles</a> by Seth Weidman</li>
  <li><a href="https://amzn.to/40ep3T7">Data Science from Scratch: First Principles with Python</a> by Joel Grus, a research engineer at the Allen Institute for Artificial Intelligence</li>
</ul>


</div>

<div class="post-tail-wrapper text-muted">

  <!-- categories -->
  
  <div class="post-meta mb-3">
    <i class="far fa-folder-open fa-fw mr-1"></i>
    
      <a href='//categories/deep-learning/'>Deep Learning</a>
  </div>
  

  <!-- tags -->
  
  <div class="post-tags">
    <i class="fa fa-tags fa-fw mr-1"></i>
      
      <a href="//tags/auto-encoder/"
          class="post-tag no-text-decoration" >auto-encoder</a>
      
  </div>
  

  <div class="post-tail-bottom
    d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
    <div class="license-wrapper">

      

        

        This post is licensed under 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         by the author.

      
    </div>

    <!--
 Post sharing snippet
-->

<div class="share-wrapper">
  <span class="share-label text-muted mr-1">Share</span>
  <span class="share-icons">
    
    
    

    
      
        <a href="https://twitter.com/intent/tweet?text=Auto-encoder%20-%20From%20AE%20to%20VAE%20with%20Pytorch%20-%20Code%20with%20Linh&url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fauto-encoder-from-ae-to-vae-with-pytorch%2F" data-toggle="tooltip" data-placement="top"
          title="Twitter" target="_blank" rel="noopener" aria-label="Twitter">
          <i class="fa-fw fab fa-twitter"></i>
        </a>
    
      
        <a href="https://www.facebook.com/sharer/sharer.php?title=Auto-encoder%20-%20From%20AE%20to%20VAE%20with%20Pytorch%20-%20Code%20with%20Linh&u=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fauto-encoder-from-ae-to-vae-with-pytorch%2F" data-toggle="tooltip" data-placement="top"
          title="Facebook" target="_blank" rel="noopener" aria-label="Facebook">
          <i class="fa-fw fab fa-facebook-square"></i>
        </a>
    
      
        <a href="https://t.me/share/url?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fauto-encoder-from-ae-to-vae-with-pytorch%2F&text=Auto-encoder%20-%20From%20AE%20to%20VAE%20with%20Pytorch%20-%20Code%20with%20Linh" data-toggle="tooltip" data-placement="top"
          title="Telegram" target="_blank" rel="noopener" aria-label="Telegram">
          <i class="fa-fw fab fa-telegram"></i>
        </a>
    

    <i id="copy-link" class="fa-fw fas fa-link small"
        data-toggle="tooltip" data-placement="top"
        title="Copy link"
        data-title-succeed="Link copied successfully!">
    </i>

  </span>
</div>


  </div><!-- .post-tail-bottom -->

</div><!-- div.post-tail-wrapper -->


      
    
    

    </div>
  </div> <!-- #core-wrapper -->

  <!-- panel -->
  <div id="panel-wrapper" class="col-xl-3 pl-2 text-muted">

    <div class="access">
      















      















  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">Trending Tags</div>
    <div class="d-flex flex-wrap mt-3 mb-1 mr-3">

    
      
      <a class="post-tag" href="/tags/auto-encoder/">auto-encoder</a>
    

    </div>
  </div>


    </div>

    
      
      



<!-- BS-toc.js will be loaded at medium priority -->
<script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script>

<div id="toc-wrapper" class="pl-0 pr-4 mb-5">
  <div class="panel-heading pl-3 pt-2 mb-2">Contents</div>
  <nav id="toc" data-toggle="toc"></nav>
</div>


    
  </div>

</div>

<!-- tail -->

<div class="row">
  <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5">
    
      
      <!--
 Recommend the other 3 posts according to the tags and categories of the current post,
 if the number is not enough, use the other latest posts to supplement.
-->

<!-- The total size of related posts  -->


<!-- An random integer that bigger than 0  -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy}  -->








  

  
    






<!-- Fill with the other newlest posts  -->



  
    
    
  




    
      
      <!--
  Navigation buttons at the bottom of the post.
-->

<div class="post-navigation d-flex justify-content-between">
  
  <div class="btn btn-outline-primary disabled"
    prompt="Older">
    <p>-</p>
  </div>
  

  
  <div class="btn btn-outline-primary disabled"
    prompt="Newer">
    <p>-</p>
  </div>
  

</div>

    
      
      <!--  The comments switcher -->

  
  <!-- https://giscus.app/ -->
<script type="text/javascript">
  $(function () {
    const origin = "https://giscus.app";
    const iframe = "iframe.giscus-frame";
    const lightTheme = "light";
    const darkTheme = "dark_dimmed";
    let initTheme = lightTheme;

    if ($("html[data-mode=dark]").length > 0
        || ($("html[data-mode]").length == 0
            && window.matchMedia("(prefers-color-scheme: dark)").matches)) {
      initTheme = darkTheme;
    }

    let giscusAttributes = {
      "src": "https://giscus.app/client.js",
      "data-repo": "hlinh96it/hlinh96it.github.io",
      "data-repo-id": "R_kgDOJFy1Ig",
      "data-category": "Announcements",
      "data-category-id": "DIC_kwDOJFy1Is4CUrGp",
      "data-mapping": "pathname",
      "data-reactions-enabled": "1",
      "data-emit-metadata": "0",
      "data-theme": initTheme,
      "data-input-position": "top",
      "data-lang": "en",
      "crossorigin": "anonymous",
      "async": ""
    };

    let giscusScript = document.createElement("script");
    Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
    document.getElementById("tail-wrapper").appendChild(giscusScript);

    addEventListener("message", (event) => {
      if (event.source === window && event.data &&
            event.data.direction === ModeToggle.ID) {
        /* global theme mode changed */
        const mode = event.data.message;
        const theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme);

        const message = {
          setConfig: {
            theme: theme
          }
        };

        const giscus = document.querySelector(iframe).contentWindow;
        giscus.postMessage({ giscus: message }, origin);
      }

    });

  });
</script>



    
  </div>
</div>


      </div>

      <!--
  The Search results
-->
<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-12 col-sm-11 post-content">
    <div id="search-hints">
      















  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">Trending Tags</div>
    <div class="d-flex flex-wrap mt-3 mb-1 mr-3">

    
      
      <a class="post-tag" href="/tags/auto-encoder/">auto-encoder</a>
    

    </div>
  </div>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>


    </div> <!-- #main-wrapper -->

    <!-- The Footer -->

<footer>
  <div class="container pl-lg-4 pr-lg-4">
    <div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3">
      <div class="footer-left">
        <p class="mb-0">
          © 2023
          <a href="https://github.com/hlinh96it">Linh H. Truong</a>.
          
          <span data-toggle="tooltip" data-placement="top"
            title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span>
          
        </p>
      </div>

      <div class="footer-right">
        <p class="mb-0">Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>.
        </p>
      </div>
    </div>
  </div>
</footer>


    

    <div id="mask"></div>

    <a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button">
      <i class="fas fa-angle-up"></i>
    </a>

    
      <div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true"
        data-animation="true" data-autohide="false">
        <div class="toast-header">
          <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close">
            <span aria-hidden="true">&times;</span>
          </button>
        </div>
        <div class="toast-body text-center pt-0">
          <p class="pl-2 pr-2 mb-3">A new version of content is available.</p>
          <button type="button" class="btn btn-primary" aria-label="Update">
            Update
          </button>
        </div>
      </div>
    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script>

<script>
SimpleJekyllSearch({
  searchInput: document.getElementById('search-input'),
  resultsContainer: document.getElementById('search-results'),
  json: '/assets/js/data/search.json',
  searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0">  <a href="{url}">{title}</a>  <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    {categories}    {tags}  </div>  <p>{snippet}</p></div>',
  noResultsText: '<p class="mt-5">Oops! No results found.</p>',
  templateMiddleware: function(prop, value, template) {
    if (prop === 'categories') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
      }
    }

    if (prop === 'tags') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
      }
    }
  }
});
</script>


    <!--
  JS selector for site.
-->

<!-- layout specified -->


  



  <!-- image lazy-loading & popup & clipboard -->
  

  







  
    

    

  



  
    

    

  



  
    

    

  




  <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js"></script>






  

  

  







  
    

    

  



  
    

    

  



  
    

    

  



  
    

    

  




  <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1.11.6/dayjs.min.js,npm/dayjs@1.11.6/locale/en.min.js,npm/dayjs@1.11.6/plugin/relativeTime.min.js,npm/dayjs@1.11.6/plugin/localizedFormat.min.js"></script>








<script defer src="/assets/js/dist/post.min.js"></script>


  <!-- MathJax -->
  <script>
  /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */
  MathJax = {
    tex: {
      inlineMath: [              /* start/end delimiter pairs for in-line math */
        ['$','$'],
        ['\\(','\\)']
      ],
      displayMath: [             /* start/end delimiter pairs for display math */
        ['$$', '$$'],
        ['\\[', '\\]']
      ]
    }
  };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml.js">
  </script>


<!-- commons -->

<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script>




  </body>

</html>

